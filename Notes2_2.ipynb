{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Notes.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4zaww_jSwW0",
        "colab_type": "text"
      },
      "source": [
        "### Decision Trees\n",
        "Decision trees have high interpretability after being trained you can literally draw them.\n",
        "Splits data on the feature which when split provides highest infomation gain.\n",
        "*  clean data with **outliers and missing values**\n",
        "*  use scikit-learn **pipelines**\n",
        "*  use scikit-learn for **decision trees**\n",
        "*  get and interpret **feature importances** of a tree-based model\n",
        "*  understand why decision trees are useful to model **non-linear, non-monotonic** relationships and **feature interactions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Gd8zmkPZKqB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5sxnitJccPT",
        "colab_type": "text"
      },
      "source": [
        "### Clean data outliners and missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r45jwl-Ucin4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check Pandas Profiling version\n",
        "import pandas_profiling\n",
        "pandas_profiling.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsKNghK4ch55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# New code for Pandas Profiling version 2.4\n",
        "from pandas_profiling import ProfileReport\n",
        "profile = ProfileReport(train, minimal=True).to_notebook_iframe()\n",
        "\n",
        "profile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6kxq4dRc4ow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def wrangle(X):\n",
        "    \"\"\"Wrangle train, validate, and test sets in the same way\"\"\"\n",
        "    \n",
        "    # Prevent SettingWithCopyWarning\n",
        "    X = X.copy()\n",
        "    \n",
        "    # About 3% of the time, latitude has small values near zero,\n",
        "    # outside Tanzania, so we'll treat these values like zero.\n",
        "    X['latitude'] = X['latitude'].replace(-2e-08, 0)\n",
        "    \n",
        "    # When columns have zeros and shouldn't, they are like null values.\n",
        "    # So we will replace the zeros with nulls, and impute missing values later.\n",
        "    cols_with_zeros = ['longitude', 'latitude']\n",
        "    for col in cols_with_zeros:\n",
        "        X[col] = X[col].replace(0, np.nan)\n",
        "            \n",
        "    # quantity & quantity_group are duplicates, so drop one\n",
        "    X = X.drop(columns='quantity_group')\n",
        "    \n",
        "    # return the wrangled dataframe\n",
        "    return X\n",
        "\n",
        "\n",
        "train = wrangle(train)\n",
        "val = wrangle(val)\n",
        "test = wrangle(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HczXy3Y-ZE7W",
        "colab_type": "text"
      },
      "source": [
        "### Pipelines\n",
        "We can combine steps with pipelines: Encode, Impute, Scale, Fit, Predict!\n",
        "\n",
        "Pipeline can be used to chain multiple estimators into one. This is useful as there is often a fixed sequence of steps in processing the data, for example feature selection, normalization and classification. Pipeline serves multiple purposes here:\n",
        "\n",
        "*  **Convenience and encapsulation.** You only have to call fit and predict once on \n",
        "your data to fit a whole sequence of estimators.\n",
        "*  **Joint parameter selection.** You can grid search over parameters of all estimators in the pipeline at once.\n",
        "*  **Safety.** Pipelines help avoid leaking statistics from your test data into the trained model in cross-validation, by ensuring that the same samples are used to train the transformers and predictors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8OvfUyKPJsv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipeline = make_pipeline(\n",
        "    ce.OneHotEncoder(use_cat_names=True),\n",
        "    SimpleImputer(strategy='mean'),\n",
        "    StandardScaler(),\n",
        "    LogisticRegression(max_iter=1000)\n",
        ")\n",
        "# Fit on train\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Score on val\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))\n",
        "\n",
        "# Predict on test\n",
        "y_pred = pipeline.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_LTaB4bZLvo",
        "colab_type": "text"
      },
      "source": [
        "### Feature importances of a tree-based model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xHoB7XnZTTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}